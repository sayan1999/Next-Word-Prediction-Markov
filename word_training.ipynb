{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read function utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(textfile):\n",
    "    file = open(textfile, 'r')\n",
    "    text = file.readlines()\n",
    "    file.close()\n",
    "    return \"\\n\".join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files from directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "textfiles = ['./dataset/' + filename for filename in os.listdir('./dataset')]\n",
    "all_text = \"\\n\".join([readfile(file) for file in textfiles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize sentences and words\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "all_tokenized_sentences=[]\n",
    "for sent in sent_tokenize(all_text):\n",
    "    all_tokenized_sentences.append([token for token in word_tokenize(sent)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process sentence tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "processed_sentences = [[sent.lower() for sent in tokenized_sent] for tokenized_sent in all_tokenized_sentences]\n",
    "processed_sentences = [sent for sent in processed_sentences if len(sent) > 2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Input and Target arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.util import ngrams\n",
    "word_input = np.array([words for sent in processed_sentences for words in ngrams(sent[:-1], 2)])\n",
    "word_output = np.array([words for sent in processed_sentences for words in sent[2:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor={}\n",
    "for a, b in zip(word_input, word_output):\n",
    "    a0=a[0]\n",
    "    a1=a[1]\n",
    "    if predictor.get(a0, None) == None:\n",
    "        predictor[a0]={a1:[b]}\n",
    "    else:\n",
    "        if predictor[a0].get(a1, None) == None:\n",
    "            predictor[a0][a1]=[b]\n",
    "        else:\n",
    "            predictor[a0][a1].append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "for a0 in predictor:\n",
    "    for a1 in predictor[a0]:\n",
    "        predictor[a0][a1] = (len(predictor[a0][a1]), predictor[a0][a1])\n",
    "    \n",
    "    predictor[a0] = {k: v for k, v in sorted(predictor[a0].items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "    for a1 in predictor[a0]:\n",
    "        predictor[a0][a1] = predictor[a0][a1][1]\n",
    "        predictor[a0][a1] = list({k: v for k, v in sorted(Counter(predictor[a0][a1]).items(), key=lambda item: item[1], reverse=True)}.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dump python object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"./objects/predictor.obj\", 'wb') as pred_file:\n",
    "    pickle.dump(predictor, pred_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
